\documentclass[11pt,reqno,final]{amsart}
\usepackage[round,elide]{natbib}
\input{header}
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,decorations,calc,math}

\title[Exact Phylodynamics]{Exact Phylodynamics via Structured Markov Genealogy Processes}
\author[King]{Aaron~A.~King}
\address{
  A.~A.~King,
  Department of Ecology \& Evolutionary Biology,
  Center for the Study of Complex Systems, and
  Department of Mathematics,
  University of Michigan,
  Ann Arbor, MI 48109 USA
}
\email{kingaa@umich.edu}
\urladdr{\href{https://kinglab.eeb.lsa.umich.edu/}{https://kinglab.eeb.lsa.umich.edu/}}
\author[Lin]{Qianying Lin}
\address{
  Q.-Y. Lin,
  Theoretical Biology and Biophysics,
  Los Alamos National Laboratory,
  Los Alamos, NM XXXXX USA
}
\author[Ionides]{Edward~L.~Ionides}
\address{
  E.~L.~Ionides,
  Department of Statistics
  University of Michigan,
  Ann Arbor, MI 48109 USA
}
\date{\today}

\hypersetup{pdftitle={Exact Phylodynamics via Structured Markov Genealogy Processes}}
\hypersetup{pdfauthor={A.A. King, Q.-Y. Lin, E.L. Ionides}}
\hypersetup{urlcolor=blue,citecolor=blue,linkcolor=blue,filecolor=blue}

<<prefix,include=FALSE,cache=FALSE,purl=FALSE>>=
prefix <- "smgp"
source("setup.R")
@
<<packages,include=FALSE,cache=FALSE>>=
library(tidyverse)
library(ggtree)
library(pomp)
library(cowplot)
library(phylopomp)
stopifnot(getRversion() >= "4.3")
stopifnot(packageVersion("pomp")>="5.1")
stopifnot(packageVersion("phylopomp")>="0.9.2")
theme_set(theme_bw(base_family="serif"))
set.seed(1159254136)
@

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

Problem of phylodynamics.
Factorization of problem into two subproblems.

Relation to previous work.
Existing methods \citep{Volz2009a,Stadler2010}.
Large-population, small sample-size approximations.

Extension of previous results \citep{King2022}.
Broader class of state-spaces.
Accommodating discrete structure.

Classes of Markov processes.
Utility and flexibility of Markov assumptions.

Population process induces Markov history and genealogy processes.
Using these, we derive equations for the likelihood of a genealogy conditional on the history.
We then integrate out the history to obtain nonlinear filtering equations, the solution of which yields the likelihood.
These readily lend themselves to a family of sequential Monte Carlo algorithms for computing the likellihood.
We demonstrate with several examples.

\section{Population processes}

Motivating examples: compartmental models.
Wide variety of models.
Linear chain trick.
Migration, superspreading, competition between strains.

Figure: example compartmental model with multiple demes.

\begin{figure}
  \begin{center}
    \resizebox{0.9\linewidth}{!}{\input{figs/model_diagrams}}
  \end{center}
  \caption{
    Examples of compartmental models.
    Demes are shaded.
    \label{fig:examples}
  }
\end{figure}

\begin{figure}
  \begin{center}
    \resizebox{0.9\linewidth}{!}{\input{figs/markov_state}}
  \end{center}
  \caption{
    Markov state transition diagram for an SEIR model.
    The state is characterized by four numbers, $S$, $E$, $I$, and $R$.
    From a given state $x$, there are four possible jumps $x\mapsto{x'}$.
    From the point of view of the induced genealogy process,
    transmission is of birth type,
    progression is of migration type,
    and recovery is of death type, while loss of immunity is of neutral type.
    In this example, when a sampling event occurs, the state does not change.
    \label{fig:markov_state}
  }
\end{figure}

\paragraph{Mathematical formalism}

Definition of state space.
Jumps and jump rates.
Demes.

Kolmogorov equations.

\subsection{Examples}

\paragraph{SEIRS model}

\paragraph{SIIR model}

\paragraph{Linear birth-death model}

\paragraph{Moran model and the Kingman coalescent}

\section{History and genealogy processes}

\subsection{Mathematical preliminaries}

State space.
Definition of $\Omega$ as space of \cadlag\ functions of time.
Define everything in terms of \cadlag\ functions rather than sequences.
Then the topology comes directly from the Skorokhod metric.
Explain we use a base measure coming from unit-rate Poisson processes.

Restrictions.
Metric, Borel $\sigma$-algebra, base measure.

Probability density.
Master process.

\paragraph{Markov jump processes}

We will assume that our population process is a non-explosive Markov jump process $\X_t$ parameterized by time $t\in\Rp$, and taking values in some space $\Xspace$.
In earlier work \citep{King2022}, we limited ourselves to the case $\Xspace=\Z^d$, but we dispense with that restriction here.
The population process is completely specified by its initial-state distribution and its generator.
In particular, we suppose that
\begin{equation}\label{eq:ic}
  \prob{\X_0=x}=p_0(x),
\end{equation}
for some choice of initial distribution, $p_0$.
We suppose there are countably many types of jumps and denote the set of jump types by $\Jumps$.
For each $u\in\Jumps$, there is a corresponding jump rate or hazard $\alpha_u$.
We impose the further requirement that $\sum_{ux'}\alpha_u(t,x,x')<\infty$ for all $t,x$.
We will always use a version of $\X_t$ in which the sample paths are right-continuous with left limits (\cadlag).

The above may be compactly summarized by means of the corresponding Kolmogorov equations, as follows.
Given $f\in L^{\infty}(\Xspace)$, let $F(s,x)\coloneq\expect{f(\X_t)\;|\;\X_s=x}$.
It then follows that, for $s<t$ and $x\in\Xspace$,
\begin{equation}\label{eq:gen}
  \begin{gathered}
    \frac{\partial{F}}{\partial{s}}(s,x)=-\int\alpha(s,x,x')\,\left[F(s,x')-F(s,x)\right]\,\dd{x'},
    \qquad
    F(t,x)=f(x).
  \end{gathered}
\end{equation}
\Cref{eq:gen} is the so-called Kolmogorov backward equation.
Its adjoint is the Kolmogorov forward equation (KFE, also called the \emph{master equation} in this context), which states that for $t\ge{0}$, $x\in\Xspace$,
\begin{equation}\label[pluralequation]{eq:kfe}
  \begin{gathered}
    \frac{\partial{w}}{\partial{t}}(t,x)=\int\!w(t,x')\,\alpha(t,x',x)\,\dd{x'}-\int\!w(t,x)\,\alpha(t,x,x')\,\dd{x'},
    \qquad
    w(0,x) = p_0(x).
  \end{gathered}
\end{equation}
If $w(t,x)$ satisfies \cref{eq:kfe}, then $w(t,x)=\prob{\X_t=x}$.

\paragraph{Definitions}

Our goal in this paper is to introduce a family of Markov processes induced by the jump process just described (\cref{fig:constellation}).
While population processes of the kind described above can be constructed in a variety of time-honored ways \citep[\eg][]{Andersen1993,Kallenberg1997}, these classical approaches are not entirely sufficient for the tree-valued Markov processes we will erect on top of the population process.
We therefore explicitly construct the probability space that underlies the stochastic processes we subsequently describe.
Unavoidably, this leads to technicalities that are necessary for the firm establishment of the properties of these processes but that may distract from the overarching goals.
Readers willing to stipulate these properties may skim the remainder of this section, in which we formally construct the probability space and make some definitions that will be needed in the sequel.

Let us define a \emph{jump} to be an ordered quadruple $(t,u,x,n)\in\Rp\times\Jumps\times\Xspace\times\Zp$.
We refer to $t$ as the \emph{time} of the jump;
$u$ is the \emph{type} of the jump;
$x$ is the state achieved at the end of the jump;
$n$ is an \emph{auxiliary number} whose use will be made clear below.
A \emph{jump sequence} is a countable sequence of jumps at increasing times.
That is,
\begin{equation*}
  \omega=\left(t_k,u_k,x_k,n_k\right)_{k=0}^{K}
\end{equation*}
is a jump sequence if and only if $K\in\Zp\cup\{\infty\}$, $u_k\in\Jumps$, $x_k\in\Xspace$, $n_k\in\Zp$ for all $k$, and $0=t_0<t_1<t_2<\dots$.
We will take our sample space, $\Omega$, to be the set of all jump sequences.
For $\omega\in\Omega$ as above, we write
\begin{equation}\label{eq:components1}
  \begin{gathered}
    T_k(\omega)\coloneq t_k, \qquad
    U_k(\omega)\coloneq u_k, \qquad
    X_k(\omega)\coloneq x_k, \qquad
    N_k(\omega)\coloneq n_k, \qquad
    K(\omega)\coloneq K
  \end{gathered}
\end{equation}
and also
\begin{equation}\label{eq:components2}
  \begin{gathered}
    T(\omega)\coloneq\left(T_k(\omega)\right)_{k=0}^{K(\omega)}, \qquad
    U(\omega)\coloneq\left(U_k(\omega)\right)_{k=0}^{K(\omega)}, \\
    X(\omega)\coloneq\left(X_k(\omega)\right)_{k=0}^{K(\omega)}, \qquad
    N(\omega)\coloneq\left(N_k(\omega)\right)_{k=0}^{K(\omega)}.
  \end{gathered}
\end{equation}
We will denote by $\mathring{\Omega}$ the set of all finite jump sequences, \ie $\mathring{\Omega}\coloneq\{\omega\in\Omega\;|\;K(\omega)<\infty\}$.

Note that every element of $\Omega$ corresponds to a unique sample path of $\X_t$.
In particular,
\begin{equation}\label{eq:Xdef}
  \X_t(\omega)=\sum_{k=0}^{K(\omega)}\!X_k(\omega)\,\indicator{\halfopen{T_k(\omega),\infty}}(t).
\end{equation}
Note that, for every $\omega\in\Omega$, the function $\X(\omega):\Rp\to\Xspace$ is thus \cadlag.
It will be useful to define $\Xt$ to be the left-limit function of $\X$:
\begin{equation*}
  \Xt(\omega,t)\coloneq
  \begin{cases}
    \lim_{s\uparrow{t}}\X(\omega,t), & t>0,\\
    \X(0), & t=0.\\
  \end{cases}
\end{equation*}

The sample space $\Omega$ has a natural partial order.
We write $\omega\preceq\omega'$ if $\omega'$ is an extension of $\omega$;
that is, if $K(\omega)\le K(\omega')$, and $\left(T_k(\omega),U_k(\omega),X_k(\omega),N_k(\omega)\right)=\left(T_k(\omega'),U_k(\omega'),X_k(\omega'),N_k(\omega')\right)$ for $k=0,\dots,K(\omega)$.
For $\omega\in\Omega$, the set
$\left\{\omega'\in\Omega\;\vert\;\omega'\preceq\omega\right\}$
is totally ordered.
Moreover, for each $\omega\in\mathring{\Omega}$, there is a unique \emph{predecessor}, $\predec{\omega}$, such that $\predec{\omega}\preceq\omega$, $\predec{\omega}\ne\omega$, and, for all $\omega'$, $\predec{\omega}\preceq\omega'\preceq\omega$ implies that either $\omega'=\predec{\omega}$ or $\omega'=\omega$.

In order to define probabilistic \emph{events}, it is necessary to define the $\sigma$-algebra of measurable subsets of $\Omega$.
We first impose the condition that $\Xspace$ be a complete, separable, measurable metric space.
We then follow \citet{King2022}, extending the Skorokhod metric \citep{Kallenberg1997,Ethier2009} to make $\Omega$ a complete, separable metric space (\ie a Polish space) and take our event space, $\Borel$, to be its Borel $\sigma$-algebra.

We now turn to the probability measure, $\mathbb{P}$, on $\Omega\cong T(\Omega){\times}U(\Omega){\times}X(\Omega){\times}N(\Omega)$.
We will specify this by giving its density.
%% We will specify this by giving its density with respect to a base measure.
%% A natural base measure on $T(\Omega)$ is the probability measure of the unit-rate Poisson point process \citep{Andersen1993,Kallenberg1997};
%% the measure on $\Xspace$ extends naturally to a product measure on $X(\Omega)$;
%% the counting measure serves for the discrete component $U(\Omega){\times}N(\Omega)$.
%% Let $\pi$ denote the product of these three measures.
%% We define a probability measure on $\Omega$ by specifying its density with respect to $\pi$.
In particular, for each $u\in\Jumps$, $x,x'\in\Xspace$, we suppose $\auxmeas_{u,x,x'}$ is a given probability measure on $\Zp$;
these will take specific forms below.
For $t\in\Rp$ and $\omega\in\restrict{\Omega}{t}$, define the probability density function
\begin{equation}\label{eq:probmeas}
  P_t(\omega)\:\coloneq\:p_0(\X_0)\,\prod_{k=1}^{K}\left(\alpha_{U_k}(T_k,\Xt_{T_k},\X_{T_k})\,\auxmeas_{U_k,\Xt_{T_k},X_{T_k}}(N_k)\right)\exp{\left(-\int_0^t\sum_{ux'}{\alpha_u(s,\X_s,x')}\,\dd{s}\right)},
\end{equation}
\normalsize
the latter sum being taken over $u\in\Jumps$, $x'\in\Xspace$.
Here, for the sake of readability, we have suppressed the dependence of the random variables $\X_t$, $K$, $T_k$, $U_k$ and $N_k$ on $\omega$.
%% It is readily verified that, for all $t$, $P_t$ is a probability density with respect to $\pi$.

\paragraph{History process}

Next among our constellation of related processes (\cref{fig:constellation}) is the \emph{history process}, which encapsulates the entire history of $\X$ up to time $t$.
Specifically, for $\omega\in\Omega$, we define
\begin{equation*}
  \Hist_t(\omega) \coloneq \left(t,\left(T_k(\omega),U_k(\omega),X_k(\omega)\right)_{k=0}^{K(\restrict{\omega}{t})}\right),
\end{equation*}
where $T_k$, $U_k$, $X_k$, and $K$ are as in \cref{eq:components1}.
Thus $\Hist_t$ contains exactly those elements of $\omega$ that are relevant to the history of the population process $\X_t$.
It is trivial to verify that $\Hist_t$ is Markov and to compute its probability density.
In particular, given any history $h_t=\left(t,\left(t_k,u_k,x_k\right)_{j=0}^{K}\right)$,
the marginal density at $h_t$ is readily seen to be
\begin{equation*}
  \begin{aligned}
    P_{\Hist_t}(h_t)\coloneq &p_0(x_0)\,\prod_{k=1}^{K}\left\{\alpha_{u_k}(t_k,x_{k-1},x_k)\,\exp{\left(-\int_{t_{k-1}}^{t_k}\sum_{ux'}{\alpha_u(s,x_{k-1},x')}\,\dd{s}\right)}\right\}\\
    &\qquad\times\,\exp{\left(-\int_{t_{K}}^{t}\sum_{ux'}{\alpha_u(s,x_{K},x')}\,\dd{s}\right)}.
  \end{aligned}
\end{equation*}

\paragraph{Inventory process}

Our main interest is in tracking the genealogical relationships among the lineages in our demes.
Accordingly, we will assign each individual lineage a unique number.
let $\Inv_t:\Rp\to\Demesplus^{\Zp}$ be such that $\Inv_t(n)=i$ if and only if lineage $n$ is in deme $i$ at time $t$.
If $t$ is before the birth or after the death of $n$, $\Inv_t(n)=\eth$.
Note that $n_i(\X_t)=\left\vert\left\{n\;\vert\;\Inv_t(n)=i\right\}\right\vert$ for all $t\in\Rp$ and $i\in\Demes$.


\paragraph{Genealogy process}

\paragraph{Pruning}

\paragraph{Filter equations}

\begin{defn}
  Suppose $X_t$ is a Markov process with Kolmogorov forward equation (KFE)
  \begin{equation}\label{eq:kfe2}
    \begin{gathered}
      \frac{\partial{w}}{\partial{t}}=\int\!w(t,x')\,\alpha(t,x',x)\,\dd{x'}-\int\!w(t,x)\,\alpha(t,x,x')\,\dd{x'},
      \qquad
      w(0,x)=p_0(x).
    \end{gathered}
  \end{equation}
  Suppose that $B(x,x')>0$ and $\lambda(t,x)>0$ are given functions, and $t_1<t_2<{\dots}<t_K$ is a given sequence of times.
  We say that the equations
  \begin{gather}
    \frac{\partial{w}}{\partial{t}}=\int\!w(t,x')\,\alpha(t,x',x)\,B(x',x)\,\dd{x'}-\int\!w(t,x)\,\alpha(t,x,x')\,\dd{x'}-\lambda(t,x)\,w(t,x),\label{eq:filtereq1}\\
    w(t_k,x)=\int\!\wt(t_k,x')\,\frac{\alpha(t,x',x)}{\mu}\,B(x',x)\,\dd{x'},\quad k=1,\dots,K,\label{eq:filtereq2}\\
    w(0,x)=p_0(x).
  \end{gather}
  are the \emph{filter equations} for $X_t$ with \emph{boost} $B$, \emph{decay} $\lambda$, \emph{initial density} $p_0$, and \emph{observation times} $t_k$.
\end{defn}

The useful fact about filter equations is that they afford a means of computing the likelihood of a given sequence of events.
This is facilitated by the following
\begin{lemma}\label{lemma:filtereq}
  \Cref{eq:filtereq1} is satisfied by $w(t,x)=\int{v\,U(t,x,v)\,\dd{v}}$, where $U$ satisfies the KFE
  \begin{equation}\label{eq:filterlemma}
    \begin{aligned}
      \frac{\partial{U}}{\partial{t}}=&\int{U(t,x',v')\,\alpha(t,x',x)\,\delta(v,B(x',x)\,v')\,\dd{x'}\,\dd{v'}}\\
      &\qquad-\int{U(t,x,v)\,\alpha(t,x,x')\,\delta(v',B(x,x')\,v)\,\dd{x'}\,\dd{v'}}
      +\tfrac{\partial}{\partial{v}}\left[\lambda(t,x)\,v\,U(t,x,v)\right].
    \end{aligned}
  \end{equation}
  Here, $\delta(v,v')$ is the familiar Dirac $\delta$.
\end{lemma}
\begin{proof}
  \begin{equation*}
    \begin{aligned}
      \frac{\partial{w}}{\partial{t}}
      =&\int{v\,\frac{\partial{U}}{\partial{t}}(t,x,v)\,\dd{v}}\\
      =&\int{v\,U(t,x',v')\,\alpha(t,x',x)\,\delta(v,B(x',x)v')\,\dd{v}\,\dd{x'}\,\dd{v'}}\\
      &\qquad-\int{v\,U(t,x,v)\,\alpha(t,x,x')\,\delta(v',B(x,x')v)\,\dd{v}\,\dd{x'}\,\dd{v'}}\\
      &\qquad+\int{v\,\tfrac{\partial}{\partial{v}}\left[\lambda(t,x)\,v\,U(t,x,v)\right]\,\dd{v}}.\\
    \end{aligned}
  \end{equation*}
  Evaluating the first integral with respect to $v$, the second with respect to $v'$, and the third by parts, we obtain
  \begin{equation*}
    \begin{aligned}
      \frac{\partial{w}}{\partial{t}}
      =&\int{v'\,U(t,x',v')\,\alpha(t,x',x)\,B(x',x)\,\dd{v'}\,\dd{x'}}
      -\int{v\,U(t,x,v)\,\alpha(t,x,x')\,\dd{v}\,\dd{x'}}\\
      &\qquad-\lambda(t,x)\,\int{v\,U(t,x,v)\,\dd{v}},
    \end{aligned}
  \end{equation*}
  which is simplified to obtain \cref{eq:filtereq1}.
\end{proof}

We recognize in \cref{eq:filterlemma} the KFE of a certain process $(X_t,V_t)$.
In particular, $X_t$ is a jump process with KF \cref{eq:kfe2}.
The $V_t$ process has jumps wherever $X_t$ does, such that when $X_t$ jumps $x\mapsto{x'}$, $V_t$ jumps by a factor of $B(x,x')$.
Between jumps, $V_t$ decays deterministically and exponentially at rate $\lambda(t,x)$.
If we view $V_t$ as a weight, then \cref{lemma:filtereq} says that the weighted average of $X_t$ evolves according to \cref{eq:filtereq1}.

\paragraph{Lineages, event-counter, deme-residence}

Let $\Lin=\Lin(\Gen)$ denote the finite set of all samples represented in genealogy $\Gen$.
Let $\prec2$ be any ordering of $\Lin$ that is compatible with ancestry.
That is, if $j,j'\in\Lin$ are such that $j$ is ancestral to $j'$, then we must have $j\prec2{j'}$.
Using this ordering, we can uniquely associate each point on a genealogical tree with the least of those lineages that descend from that point.
In particular, any lineage $j\in\Lin$, corresponding to a sample taken at time $t^s_j$, can be traced backward from node to node until either it coalesces with some lesser lineage at some time $t^o_j>0$ or a root is reached (in which case, we define $t^o_j=0$).
Each node encountered along the way represents a genealogical event from which $j$ emerges.
Moreover, at each time $t\in\halfopen{t^o_j,t^s_j}$, lineage $j$ is in precisely one of the demes $D$.
However, for $t\notin\halfopen{t^o_j,t^s_j}$, lineage $j$ does not exist.
To express this, we say that lineage $j$ is in the \emph{undeme}, which we denote using the symbol $\eth$.
We define $\Demesplus\coloneq\Demes\cup\{\eth\}$.

It will be useful to define a function that captures all the relevant features of a pruned genealogy.
Accordingly, let $\Yspace=(\Zp\times\Demesplus\times\Lin)^{\Lin}$ and define $y:\Rp\to\Yspace$ so that, for $j\in\Lin$ and $t\in\Rp$:
\begin{compactenum}[(a)]
\item $\ct(y_j(t))\in\Zp$ is a counting process which increases by 1 at each event along lineage $j$.
\item $\deme(y_j(t))\in\Demesplus$ indicates in which deme lineage $j$ lies at time $t$.
  In particular $\deme(y_j(t))=\eth$ if $t\notin\halfopen{t^o_j,t^s_j}$.
\item $\anc(y_j(t))\in\Lin$ indicates the lineage in which the ancestors of lineage $j$ are found.
  In particular, $\anc(y_j(t))=j$ for $t\ge{t^o_j}$, but $\anc(y_j(t))$ is well defined for all $j$ and $t$.
\end{compactenum}
One can verify that $y$ is \cadlag.
Define $\yt(t)=\lim_{s\uparrow{t}}y(s)$.

To visualize these functions, one can make a correspondence between demes and colors.
Then a pruned genealogy is visualized as a tree with colored branches.
Knowing the function $\deme(y)$ is equivalent to knowing the coloring, while $\ct(y)$ determines the locations of events in the genealogy and $\anc(y)$ determines the topology.
Note in particular that $y_j(t)\ne\yt_j(t)$ if and only if $t$ is the time of an event from which lineage $j$ emerges.

\paragraph{Lineage count, saturation}

In the following, we will find that we need to count the deme-specific numbers of lineages present at a given time.
Accordingly, for any $\Lin'\subseteq{\Lin}$, $\eta\in(\Zp\times\Demesplus\times\Lin')^{\Lin'}$, and $i\in\Demes$, let us define
\begin{equation*}
  \ell_i(\eta)\coloneq{\left\vert\left\{j\in\Lin'\;\vert\;\deme(\eta_j)=i\right\}\right\vert}\in\Zp, \qquad \ell(\eta)\coloneq(\ell_i(\eta))_{i\in\Demes}\in{\Zp^\Demes}.
\end{equation*}
Note that lineages $j$ for which $\eta_j=\eth$ are not counted.
With this definition, it follows that $\ell_i(y(t))$ is the number of lineages in deme $i$ at time $t$.

We will also have occasion to refer to the deme-specific number of lineages emerging from a given event.
Accordingly, for $\Lin'\subseteq{\Lin}$, $\eta,\eta'\in(\Zp\times\Demesplus\times\Lin')^{\Lin'}$, and $i\in\Demes$, let us define
\begin{equation*}
  s_i(\eta,\eta')\coloneq{\left\vert\left\{j\in{\Lin'}\;\vert\;\deme(\eta_j)=i\ \ \&\ \ \ct(\eta'_j)=\ct(\eta_j)+1\right\}\right\vert}, \qquad s(\eta,\eta')\coloneq(s_i(\eta,\eta'))_{i\in\Demes}\in{\Zp^\Demes}.
\end{equation*}
With this definition, $s_i(\yt(t),y(t))$ is the number of lineages in deme $i$ that emerge from an event at time $t$ and that, if $t$ is not an event time, then $s(\yt(t),y(t))=0$.

\subsection{Obscuration}

\section{Results}

\begin{defn}
  For $n,r,\ell,n\in{\Zp^\Demes}$, define the multivariable binomial coefficient by
  \begin{equation*}
    \binom{n}{r}\coloneq\prod_{i\in\Demes}\binom{n_i}{r_i}.
  \end{equation*}
  Using this, we define the \emph{binomial ratio}
  \begin{equation*}
    \BoxProb{n}{\ell}{r}{s}\coloneq\frac{\binom{n-\ell}{r-s}}{\binom{n}{r}}\in{[0,1]}.
  \end{equation*}
\end{defn}

In consequence of the Chu-Vandermonde identity, we have
\begin{equation}
  \sum_{s\in\Zp^{\Demes}}\BoxProb{n}{\ell}{r}{s}\binom{\ell}{s}=1
\end{equation}

\paragraph{Likelihood of a pruned genealogy}

Now certain population-process events at certain times are incompatible with any given pruned genealogy.
Example: a sample event where no sample is seen, or a migration event involving a change of deme not observed in the pruned genealogy.
Define the function $Q_u(\eta,\eta')=1$ if a change $\eta\to\eta'$ at time $t$ is compatible with an event of type $u$ at that time, and $Q_u=0$ otherwise.
In other words, $Q_u$ is the indicator function for the condition that there exist $\omega\in\Omega$, $t\in\Rp$, and $k\in\Zp$ such that $t=T_k(\omega)$, $u=U_k(\omega)$, $\yt(t,\omega)=\eta$, and $y(t,\omega)=\eta'$.
Using this, we define
\begin{equation*}
  \phi_u(\xi,\eta,\eta')\coloneq\BoxProb{n(\xi)}{\ell(\eta')}{r_u}{s(\eta,\eta')}\,Q_u(\eta,\eta').
\end{equation*}

\begin{thm}
  \begin{equation*}
    \prob{\Gen\vert\Hist}=\prod_{(u,t,x)\in\Hist}\phi_u(x,\yt(t),y(t)).
  \end{equation*}
\end{thm}

\begin{figure}
  \begin{center}
    \input{figs/thm1diag}
  \end{center}
  \caption{\label{fig:thm1diag}}
\end{figure}

\begin{center}
  \input{figs/triangle1}
\end{center}

\begin{equation*}
  \frac{r!}{(r-s)!}\cdot\frac{(n-\ell)!}{n!}\cdot\frac{(n-r)!}{(n-r-\ell+s)!}
  =\frac{r!(n-r)!}{n!}\cdot\frac{(n-\ell)!}{(n-\ell-r+s)!(r-s)!}
  =\BoxProb{n}{\ell}{r}{s}
\end{equation*}

Suppose we have a pruned genealogy $\Prune^*$, defined on the time-interval $[0,T]$, with event times $0=t_0<t_1<\cdots<t_n=T$.
From the theorem, we have, for $t\notin\event(\Prune^*)$,
\begin{equation}
  \frac{\partial{w}}{\partial{t}}=\sum_{u}\int\!w(t,x')\,\alpha_u(t,x',x)\,\phi_u\big(x,y(t),y(t)\big)\,\dd{x'}
  -\sum_{u}\int\!w(t,x)\,\alpha_u(t,x,x')\,\dd{x'}.
\end{equation}
At event times, $t\in\event(\Prune^*)$, one has
\begin{equation}\label{eq:prune_filt_disc}
  w(t,x)=\sum_{u}\int\!\wt(t,x')\,\frac{\alpha_u(t_k,x',x)}{\mu}\,\phi_u\big(x,\yt(t),y(t)\big)\,\dd{x'}\\,
\end{equation}
In addition, there are the initial and boundary conditions
\begin{equation}
  \begin{gathered}
    w(0,x)=p_0(x), \qquad w(t,x)=0\quad\text{whenever}\quad n(x)<\ell(y(t)).
  \end{gathered}
\end{equation}

\paragraph{Likelihood of an obscured genealogy}

Let $\kappa^{\Vis}$ be the indicator function for the condition that a pruned genealogy is compatible with a given obscured genealogy.
In particular, given an obscured genealogy $\Vis$, set $\kappa^{\Vis}_u(t,x,x',\eta,\eta')=\Indicator{\exists\Prune\ \st\ \kappa^{\Prune}_u(t,x,x',y,y')=1\ \&\ \obs(\Prune)=\Vis}$.

\section{Examples}

\subsection{SEIRS}

Jumps: $\Jumps=\{\mathrm{Inf},\mathrm{Prog},\mathrm{Recov},\mathrm{Wane},\mathrm{Birth},\mathrm{Death_S},\mathrm{Death_E},\mathrm{Death_I},\mathrm{Death_R},\mathrm{Sample}\}$.

Demes: $\Demes=\{\mathrm{E},\mathrm{I}\}$.

Jump rates:
\begin{itemize}
\item $\alpha_{\mathrm{Inf}}(t,x,x')=\beta(t)\,\frac{x^{\mathrm{S}}x^{\mathrm{I}}}{N(t)}\,\Indicator{x'=x+(-1,1,0,0)}$
\item $\alpha_{\mathrm{Prog}}(x,x')=\rho\,x^{\mathrm{E}}\,\Indicator{x'=x+(0,-1,1,0)}$
\item $\alpha_{\mathrm{Recov}}(x,x')=\gamma\,x^{\mathrm{I}}\,\Indicator{x'=x+(0,0,-1,1)}$
\item $\alpha_{\mathrm{Wane}}(x,x')=\upsilon\,x^{\mathrm{R}}\,\Indicator{x'=x+(1,0,0,-1)}$
\item $\alpha_{\mathrm{Sample}}(t,x,x')=\psi\,x^I\,\Indicator{x'=x}$
\item $\alpha_{\mathrm{Birth}}(t,x,x')=B(t)\,\Indicator{x'=x+(1,0,0,0)}$
\item $\alpha_{\mathrm{Death}_k}(x,x')=\mu\,x^k\,\Indicator{x'^j=x^j-\delta_{jk}}$, $k\in\{\mathrm{S},\mathrm{E},\mathrm{I},\mathrm{R}\}$
\end{itemize}

%% Nonlinear filtering equation:
%% \begin{equation}
%%   \begin{aligned}
%%     \frac{\partial{w}}{\partial{t}}(t,x,y,z)=&B(t)\,\left[\sum_{y'z'}w\big(t,x-(1,0,0,0),y',z'\big)-w\big(t,x,y,z\big)\right]\\
%%     &\qquad+\sum_{k\in\{\mathrm{S},\mathrm{E},\mathrm{I},\mathrm{R}\}}\mu\,(x^k+1)\,w(t,x+\delta_{k})-\mu\,x^k\,w(t,x)\\
%%     &\qquad+\upsilon\,x^{\mathrm{R}}\,w(t,x-(1,0,0,-1))\\
%%   \end{aligned}
%% \end{equation}

\section{Discussion}


\bibliographystyle{preprint}
\bibliography{phylopomp}

\end{document}
