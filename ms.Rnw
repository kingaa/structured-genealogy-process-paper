\documentclass[10pt,reqno,final]{amsart}

\input{header}

\title[Exact Phylodynamics]{Exact Phylodynamics via Structured Markov Genealogy Processes}
\author[King]{Aaron~A.~King}
\address{
  A.~A.~King,
  Department of Ecology \& Evolutionary~Biology,
  Center for the Study of Complex~Systems, and
  Department of Mathematics,
  University of Michigan,
  Ann~Arbor, MI~48109~USA\\
  Santa~Fe~Institute,
  1399 Hyde~Park~Road,
  Santa~Fe, NM~87501~USA
}
\email{kingaa@umich.edu}
\urladdr{\href{https://kinglab.eeb.lsa.umich.edu/}{https://kinglab.eeb.lsa.umich.edu/}}
\author[Lin]{Qianying~Lin}
\address{
  Q.-Y.~Lin,
  Theoretical Biology and Biophysics,
  Los~Alamos National Laboratory,
  Los~Alamos, NM~87545~USA
}
\author[Ionides]{Edward~L.~Ionides}
\address{
  E.~L.~Ionides,
  Department of Statistics
  University of Michigan,
  Ann~Arbor, MI~48109~USA
}
\date{\today}

\hypersetup{pdftitle={Exact Phylodynamics via Structured Markov Genealogy Processes}}
\hypersetup{pdfauthor={A.A. King, Q.-Y. Lin, E.L. Ionides}}
\hypersetup{urlcolor=blue,citecolor=blue,linkcolor=blue,filecolor=blue}

<<prefix,include=FALSE,cache=FALSE,purl=FALSE>>=
prefix <- "sgp"
source("setup.R")
@
<<packages,include=FALSE,cache=FALSE>>=
library(tidyverse)
library(ggtree)
library(pomp)
library(cowplot)
library(viridis)
library(phylopomp)
stopifnot(getRversion() >= "4.3")
stopifnot(packageVersion("pomp")>="5.5")
stopifnot(packageVersion("phylopomp")>="0.10.3")
theme_set(theme_bw(base_family="serif"))
set.seed(1159254136)
@

\begin{document}

\begin{abstract}
  We derive an algorithm for the exact computation of the likelihood of an observed transmission tree.
\end{abstract}

\maketitle

\section{Introduction}

With the advent of inexpensive genome sequencing technologies, routine molecular surveillance has become an important tool in the epidemiologist's kit.
When an infectious agent evolves quickly enough so that information on its history of transmission accumulates in its genome, yet not so quickly that it is dissipated, it is possible to extract this information to gain insight into the determinants of transmission.
With sufficiently dense sampling, it can be possible to reconstruct the specific history of who has infected whom, which can aid identification of the correlates of transmission and immunity and the features of infections.
More typically, one can attempt to learn about these features via the estimation of a model of the transmission process on the basis of relatively sparse samples.
In particular, one can formalize one or more mathematical models of transmission, estimate their parameters, and comparing their ability to explain data, following a standard statistical paradigm.
For the purposes of this paper, we refer to the latter program as \emph{phylodynamics}.

Because there is commonly broad uncertainty regarding the structure of the transmission process, for example due to heterogeneities in transmission rates and susceptibilities, complex behavior patterns, etc., methods that have the plug-and-play property are particularly useful.
Such techniques for inference based on time series are well understood and widely used.
When the data lie in some Euclidean space, they can commonly be modeled as draws from some error distribution conditional on the latent state of the transmission process.
However, when the data are genealogies (also called phylogenies) representing the relationships of shared ancestry among genomic samples, the data-space is non-Euclidean and the appropriate models connecting the data to the latent state are non-trivial.
Here, we derive expressions for the exact likelihood of a genealogy generated through sampling genomes from an arbitrary discretely-structured, Markov latent state process.

Problem of phylodynamics.
Factorization of problem into two subproblems.
Problems with this approach \citep{Smith2017}.

Relation to previous work.
Existing methods \citep{Volz2009a,Stadler2010}.
Large-population, small sample-size approximations.

For structured but deterministic models, approach of \citet{Volz2012,Rasmussen2014a}, based on approximation as birth-death processes:
approximation no longer needed.

Modeling of the sampling process.

Extension of previous results \citep{King2022}.
Broader class of state-spaces.
Accommodating discrete structure.

Classes of Markov processes.
Utility and flexibility of Markov assumptions.

Population process induces Markov history and genealogy processes.
Using these, we derive equations for the likelihood of a genealogy conditional on the history.
We then integrate out the history to obtain nonlinear filtering equations, the solution of which yields the likelihood.
These readily lend themselves to a family of sequential Monte Carlo algorithms for computing the likelihood.
We demonstrate with several examples.

In the following, we show a Markov population process of the kind that is a staple in epidemiology induces a Markov process on the space of genealogies.
We then show how one can compute the likelihood of a given genealogy.

\section{Mathematical preliminaries}

\subsection{Notation}

Throughout the paper, we will adopt the convention that a bold-face symbol (\eg $\Xr$), denotes a random element.
We will be concerned with a variety of stochastic processes, in both discrete and continuous time.
In both cases, we will use a subscript to indicate the time parameter: \eg $\Xr_t$ or $\Gr_k$, where $t$ takes values in the non-negative reals $\Rp$ and $k$ in the non-negative integers $\Zp$.
In the case of continuous-time processes, we will assume that sample paths are \cadlag\ \ie, right-continuous with left limits.
We will frequently need to refer to the left-limit of such a process.
Accordingly, if $\Phir_t$ is a \cadlag\ random process, we define
\begin{equation*}
  \Phirt_t\colonequals
  \begin{cases}
    \displaystyle\lim_{s\,\uparrow\,{t}}\;\Phir_{s}, & t>0,\\[2ex]
    \Phir_0, & t=0.\\
  \end{cases}
\end{equation*}
Note that $\Phirt_t$ is thus left-continuous with right limits.

If $\Phir_t$, $t\in\Rp$ is a pure jump process, knowledge of its sample path is equivalent to knowledge of the number, $\Kr_t$, of jumps it has taken as of time $t$, the jump times $\Trh_k$, and the embedded chain $\Phirh^{}_k\coloneq{\Phir_{\Trh^{}_k}}$, $k=0,\dots,\Kr^{}_t$.
In particular, if we adopt the convention that $\Trh_0=0$ and $\Trh_{\Kr_t+1}=t$, then
$\Phir_t=\Phirh_k$ for $t\in\halfopen{\Trh_k,\Trh_{k+1}}$, $k=0,\dots,\Kr_t$.

\subsection{Population process}

Motivating examples:
compartmental models in ID epidemiology,
phylogenetics and systematics.
Wide variety of models are of interest (\cref{fig:example_models}).
Linear chain trick.
Migration, superspreading, competition between strains.

\begin{figure}
  \input{figs/example_models}
\end{figure}

We will assume that our population process is a time-inhomogeneous Markov jump process, $\Xr_t$, $t\in\Rp$, taking values in some space $\Xspace$.
In earlier work \citep{King2022}, we limited ourselves to the case $\Xspace=\mathbb{Z}^d$, but here we assume only that $\Xspace$ is a complete metric space with a countable dense subset, \ie a Polish space.
The population process is completely specified by its initial-state density, $p_0$, and its transition rates $\alpha$.
In particular, we suppose that
\begin{equation}
  \label{eq:ic}
  \Prob{\Xr_0\in\mathcal{E}}=\int_{\mathcal{E}}{p_0(x)\,\dd{x}}
\end{equation}
for all measurable sets $\mathcal{E}\subseteq\Xspace$.
For any $t\in\Rp$, $x,x'\in\Xspace$, we think of the quantity $\alpha(t,x,x')$ as the instantaneous hazard of a jump from $x$ to $x'$.
More precisely, the transition rates have the following properties:
\begin{equation*}
  \begin{gathered}
    \alpha(t,x,x')\ge{0}, \qquad \int_{\Xspace}{\alpha(t,x,x')\,\dd{x'}}<\infty,\\
  \end{gathered}
\end{equation*}
for all $t\in\Rp$ and $x,x'\in\Xspace$.
\AAK{[We could mention that we use the continuity of $\alpha$ with respect to $t$ in some of the following, but that this condition can be relaxed.]}
Henceforth, we understand that integrals are taken over all of $\Xspace$ unless otherwise specified.
Let $\Kr_t$ be the number of jumps that $\Xr$ has taken by time $t$.
We assume that $\Kr_t$ is a simple counting process so that
\begin{equation*}
  \begin{gathered}
    \CondProb{\Kr_{t+\Delta}=n+1}{\Kr_{t}=n}=\Delta\,\int{\alpha(t,x,x')\,\dd{x'}}+o(\Delta),\\
    \CondProb{\Kr_{t+\Delta}>n+1}{\Kr_{t}=n}=o(\Delta),\\
    \CondProb{\Xr_{t+\Delta}\in\mathcal{E}}{\Xr_{t}=x, \Kr_{t+\Delta}-\Kr_{t}=1}=\frac{\int_{\mathcal{E}}{\alpha(t,x,x')\,\dd{x'}}}{\int{\alpha(t,x,x')\,\dd{x'}}}.
  \end{gathered}
\end{equation*}
We will further assume that the number of jumps that occur in a finite time-interval is finite: $\Prob{\Kr_t<\infty}=1$ for all $t$.

\subsubsection{Kolmogorov forward equation}

The above may be compactly summarized by stating that if $v(t,x)$ satisfies the Kolmogorov forward equation (KFE),
\begin{equation}
  \label{eq:kfe}
  \frac{\partial{v}}{\partial{t}}(t,x)=\int\!v(t,x')\,\alpha(t,x',x)\,\dd{x'}-\int\!v(t,x)\,\alpha(t,x,x')\,\dd{x'},
\end{equation}
and if, moreover, $v(0,x) = p_0(x)$,
then $\int_{\mathcal{E}}\!{v(t,x)\,\dd{x}}=\Prob{\Xr_t\in\mathcal{E}}$ for every measurable $\mathcal{E}\subseteq{\Xspace}$.
\Cref{eq:kfe} is sometimes called the \emph{master equation} for $\Xr_t$.

Another perspective on the Markov processes is to be had from its Markov state transition diagram (\cref{fig:markov_state}).

\begin{figure}
  \input{figs/markov_diagram}
\end{figure}

\subsubsection{Structured populations, demes, and deme occupancy}
\label{sec:demes}

In an \emph{unstructured} Markov population process, every lineage is exactly like every other.
\citet{King2022} showed how every such process induces an unstructured Markov genealogy process.
Here, our aim is to expand the theory considerably by allowing our population of lineages to have discrete structure.
In particular, we suppose that there are a countable set of subpopulations that may differ in their vital rates, but within each of which, individual lineages are statistically identical.
We call these subpopulations \emph{demes}, and use the symbol $\Demes$ to denote an index set for them.
We define the \emph{deme occupancy} function $n:\Demes\times\Xspace\to\Zp$ so that
for $i\in\Demes$, $x\in\Xspace$, $n_i(x)$ is the number of lineages in deme $i$ when the population is in state $x$.

\subsection{Jump marks}

In the following, it will be useful to divide the jumps of the population process $\Xr_t$ into distinct categories.
For this purpose, we let $\Jumps$ be a countable set of jump \emph{marks} such that
\begin{equation*}
  \alpha(t,x,x')=\sum_u{\alpha_u(t,x,x')}.
\end{equation*}
\Cref{fig:markov_state} shows an example with five distinct marks.
Here and in the following, sums over $u$ are taken over the whole of $\Jumps$ unless otherwise indicated.

Let us define the \emph{jump mark} process, $\Ur_t$, to be the mark of the latest jump as of time $t$.
As usual, we take the sample paths of $\Ur_t$ to be \cadlag.
Observe that, though $\Xr_t$ and $(\Xr_t,\Ur_t)$ are Markov processes, $\Ur_t$ is not.

\subsection{Examples}

\subsubsection{SIRS model}

\citet{King2022} worked out formulas for the exact likelihood of a genealogy induced by an SIRS model.
The theory developed in this paper applies, but since there is only one deme in this model, this is a simple case.
Its state vector is $x=(S,I,R)$ and its KFE is
\fontsize{10pt}{11pt}\selectfont
\begin{equation*}
  \begin{split}
    \frac{\partial{v}}{\partial{t}}(t,S,I,R)=
    &\frac{\beta(t)\,I\,(S+1)}{N}\,v(t,S+1,I-1,R)
    -\frac{\beta(t)\,I\,S}{N}\,v(t,S,I,R)\\
    &+\gamma\,(I+1)\,v(t,S,I+1,R-1)
    -\gamma\,I\,v(t,S,I,R)\\
    &+\omega\,(R+1)\,v(t,S-1,I,R+1)
    -\omega\,R\,v(t,S,I,R).
  \end{split}
\end{equation*}
\normalfont
Note that we have here allowed for the possibility that the transmission rate, $\beta$, depends on time.

\subsubsection{SEIRS model}

A simple, yet interesting, model with more than one deme is the SEIRS model (\cref{fig:example_models}A).
The state space is $\Rp^4$, with the state $x=(S,E,I,R)$ defined by the numbers of hosts in each of the four compartments.
It has two demes ($\Demes=\Set{\lab{E},\lab{I}}$) and the KFE
\fontsize{10pt}{11pt}\selectfont
\begin{equation*}
  \begin{split}
    \frac{\partial{v}}{\partial{t}}(t,S,E,I,R)=
    &\frac{\beta(t)\,I\,(S+1)}{N}\,v(t,S+1,E-1,I,R)
    -\frac{\beta(t)\,I\,S}{N}\,v(t,S,E,I,R)\\
    &+\sigma\,(E+1)\,v(t,S,E+1,I-1,R)
    -\sigma\,E\,v(t,S,E,I,R)\\
    &+\gamma\,(I+1)\,v(t,S,E,I+1,R-1)
    -\gamma\,I\,v(t,S,E,I,R)\\
    &+\omega\,(R+1)\,v(t,S-1,E,I,R+1)
    -\omega\,R\,v(t,S,E,I,R),
  \end{split}
\end{equation*}
\normalfont
where $N=S+E+I+R$ is the total population size.
The deme occupancy function in this case is $n(x)=(E,I)$.
Note that the terms associated with sampling cancel each other in the KFE, since, in this model, sampling has no effect on the state.

\subsubsection{Two-strain competition model}

A simple model for the competition of two strains for susceptible hosts is depicted in \cref{fig:example_models}B.
In this model, the state vector consists of seven numbers: $x=(S,E_1,E_2,I_1,I_2,R_1,R_2)$.
There are four demes ($\Demes=\Set{\lab{E}_1,\lab{E}_2,\lab{I}_1,\lab{I}_2}$) and the occupancy function is $n(x)=(E_1,E_2,I_1,I_2)$.
This model has KFE
\fontsize{10pt}{11pt}\selectfont
\begin{equation*}
  \begin{split}
    \frac{\partial{v}}{\partial{t}}=
    &\frac{\beta_1(t)\,I_1\,(S+1)}{N}\,v(t,S+1,E_1-1,E_2,I_1,I_2,R_1,R_2)
    -\frac{\beta_1(t)\,I_1\,S}{N}\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
    &+\frac{\beta_2(t)\,I_2\,(S+1)}{N}\,v(t,S+1,E_1,E_2-1,I_1,I_2,R_1,R_2)
    -\frac{\beta_2(t)\,I_2\,S}{N}\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
    &+\sigma_1\,(E_1+1)\,v(t,S,E_1+1,E_2,I_1-1,I_2,R_1,R_2)
    -\sigma_1\,E_1\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
    &+\sigma_2\,(E_2+1)\,v(t,S,E_1,E_2+1,I_1,I_2-1,R_1,R_2)
    -\sigma_2\,E_2\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
    &+\gamma_1\,(I_1+1)\,v(t,S,E_1,E_2,I_1+1,I_2,R_1-1,R_2)
    -\gamma_1\,I_1\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
    &+\gamma_2\,(I_2+1)\,v(t,S,E_1,E_2,I_1,I_2+1,R_1,R_2-1)
    -\gamma_2\,I_2\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
    &+\omega_1\,(R_1+1)\,v(t,S-1,E_1,E_2,I_1,I_2,R_1+1,R_2)
    -\omega_1\,R_1\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
    &+\omega_2\,(R_2+1)\,v(t,S-1,E_1,E_2,I_1,I_2,R_1,R_2+1)
    -\omega_2\,R_2\,v(t,S,E_1,E_2,I_1,I_2,R_1,R_2)\\
  \end{split}
\end{equation*}
\normalfont

\subsubsection{Superspreading model}

\Cref{fig:example_models}D depicts a model of superspreading.
There are three demes ($\Demes=\Set{\lab{E},\lab{I_L},\lab{I_H}}$).
The state vector is $x=(S,E,I_L,I_H,R)$ and the KFE is
\fontsize{10pt}{11pt}\selectfont
\begin{equation*}
  \begin{split}
    \frac{\partial{v}}{\partial{t}}=
    &\frac{\beta(t)\,(I_L+\theta\,I_H)\,(S+1)}{N}\,v(t,S+1,E-1,I_L,I_H,R)
    -\frac{\beta(t)\,(I_L+\theta\,I_H)\,S}{N}\,v(t,S,E,I_L,I_H,R)\\
    &\sigma\,(E+1)\,v(t,S,E+1,I_L-1,I_H,R)
    -\sigma\,E\,v(t,S,E,I_L,I_H,R)\\
    &\eps_{LH}\,(I_L+1)\,v(t,S,E,I_L+1,I_H-1,R)
    -\eps_{LH}\,I_L\,v(t,S,E,I_L,I_H,R)\\
    &\eps_{HL}\,(I_H+1)\,v(t,S,E,I_L-1,I_H+1,R)
    -\eps_{HL}\,I_H\,v(t,S,E,I_L,I_H,R)\\
    &\gamma\,(I_L+1)\,v(t,S,E,I_L+1,I_H,R-1)
    -\gamma\,I_L\,v(t,S,E,I_L,I_H,R)\\
    &\gamma\,(I_H+1)\,v(t,S,E,I_L,I_H+1,R-1)
    -\gamma\,I_H\,v(t,S,E,I_L,I_H,R)\\
    &\omega\,(R+1)\,v(t,S-1,E,I_L,I_H,R+1)
    -\omega\,R\,v(t,S,E,I_L,I_H,R).\\
  \end{split}
\end{equation*}
\normalfont

\subsubsection{Linear birth-death model}

\fontsize{10pt}{11pt}\selectfont
\begin{equation*}
  \frac{\partial{v}}{\partial{t}}=
  \lambda\,(N-1)\,v(t,N-1)
  -\lambda\,N\,v(t,N)
  +\mu\,(N+1)\,v(t,N+1)
  -\mu\,N\,v(t,N)
\end{equation*}
\normalfont

\subsubsection{Moran model and the Kingman coalescent}

\subsection{History}

Consider the Markov process $(\Xr_t,\Ur_t)$.
We define its \emph{history process}, $\Hr_t$, to be the restriction of the random function $s\mapsto(\Xr_s,\Ur_s)$ to the interval $[0,t]$.
Note that $\Hr_t$ is itself trivially a Markov process, since it contains its own history.

Alternatively, one can think of $\Hr_t$ as consisting of the sequence
$\left(\left(\Trh_k,\Xrh_k,\Urh_k\right)\right)_{k=0}^{\Kr_t}$.
In particular, conditional on $\Hr_t$, both $\Xr_t$ and $\Ur_t$ are deterministic, as are $\Kr_t$ and the embedded chains, $\Xrh_k$, $\Urh_k$, and the point process of event times $\Trh_k$.
The probability measure, $\pi^{\mathrm{H}}$, for $\Hr_t$ can be expressed in terms of these:
\fontsize{10pt}{11pt}\selectfont
\begin{equation*}
  \label{eq:Hdens}
  \pi^{\mathrm{H}}(\dd{\H_t})
  =p_{0}(\Xh_{0})\,\dd{\Xh_0}\,
  \prod_{k=1}^{K_{t}}{\alpha_{\Uh_k}\!\!\left(\Th_k,\Xh_{k-1},\Xh_{k}\right)\,\dd{\Xh_k}\,\dd{\Th_k}}
  \,\exp{\left(-\sum_{k=0}^{K_t}{\int_{\Th_{k}}^{\Th_{k+1}}{\sum_{u}{\int{\alpha_{u}(t',\Xh_{k},x')\,\dd{x'}}}}\,\dd{t'}}\right)},
\end{equation*}
\normalfont
where again, by convention, $\Th^{}_0=0$ and $\Th^{}_{K^{}_t+1}=t$.

If $\H$ is such a history, we define $\time(\H)$ to be the right endpoint of its domain and use the notation $\event{\H}\coloneq\Set{\Th^{}_1,\dots,\Th^{}_{\K_t}}\subset{[0,\time(\H)]}$ to denote the set of its jump times.

\subsection{Genealogies}
\label{sec:genealogy}

\begin{figure}
  \begin{center}
    <<geneal,fig.dim=c(4,2),out.width="50%">>=
    freeze(
      seed=382490723,
      simulate(
        "SEIR",
        Beta=3,sigma=0.5,gamma=0.2,psi=0.3,omega=0.5,
        S0=15,E0=1,I0=2,R0=0,
        time=10
      )
    ) -> x

    pal <- c("#00274CFF","#FFCB05FF")

    x |> plot(points=TRUE,prune=FALSE,obscure=FALSE,palette=pal)+
      geom_vline(xintercept=10,linewidth=0.2,color="black")
    @
  \end{center}
  \caption{
    A genealogy, $G$, specifies the relationships of shared ancestry (via its tree-structure) and deme occupancy histories (via the coloring of its branches) of a set of lineages extant at some time $\time(G)$, as well as some samples gathered at earlier times.
    Here, $\time(G)=10$ and there are two demes, $\Demes=\Set{\func{blue},\func{yellow}}$.
    Tip nodes, denoting extant lineages, are shown as black dots;
    sample nodes are shown as blue dots;
    internal nodes are indicated in green.
    Note that internal nodes occur both at branch-points and inline (\ie along branches).
    Wherever a lineage moves from one deme (color) to another, an internal node occurs;
    the converse does not necessarily hold.
    \label{fig:geneal}
  }
\end{figure}

A \emph{genealogy}, $G$, encapsulates the relationships of shared ancestry among a set of lineages that are extant at some time $\time(G)\in\Rp$, and perhaps a set of samples collected at earlier times (\cref{fig:geneal}).
A genealogy has a tree- or forest-like structure, with four distinct kinds of nodes:
\begin{inparaenum}[(i)]
\item \emph{tip nodes}, which represent labeled extant lineages;
\item \emph{internal nodes}, which represent events at which lineages diverged and/or moved from one deme to another;
\item \emph{sample nodes}, which represent labeled samples; and
\item \emph{root nodes}, at the base of each tree.
\end{inparaenum}
Each node $a$ is associated with a specific time, $\time(a)$.
In particular, if $a$ is a tip node in $G$, then $\time(a)=\time(G)$;
if $a$ is a sample node, then $\time(a)$ is the time at which the sample was taken.
Moreover, if node $a$ is ancestral to node $a'$, then $\time(a)\le{\time(a')}$ and $\time(a')-\time(a)$ is the distance between $a$ and $a'$ along the genealogy.
Without loss of generality we assume that $\time(a)=0$ for all root nodes $a$.
We let $\event{G}$ denote the set of all internal and sample node-times of the genealogy $G$;
we refer to these as \emph{genealogical event times}.

Importantly, a genealogy informs us not only about the shared ancestry of any pair of lineages, but also about where in the set of demes any given lineage was at all times.
Accordingly, we can visualize a genealogy as a tree, the nodes and edges of which are painted with a distinct color for each deme (\cref{fig:geneal}).
Note that a genealogy will in general have \emph{branch-point nodes}, \ie internal nodes with more than one descendant, but may also have internal nodes with only one descendant.
We refer to such nodes as \emph{inline nodes}.
These occur whenever the color changes along a branch, but can also occur without a color-change.

Formally, we define a genealogy, $G$, to be a triple, $(T,Z,Y)$, where $T=\time(G)\in\Rp$ is the \emph{genealogy time}, $Z$ specifies the genealogy's \emph{tree structure}, and $Y$ gives the \emph{coloring}.
In particular, let $\leaves$ be a countable set of labels and let $\part(\leaves)$ be the set of all collections of finite, mutually-disjoint subsets of $\leaves$.
That is, an element $\zeta\in{\part(\leaves)}$ is a partition of the finite set $\bigcup\zeta\subseteq\leaves$.
Partition \emph{fineness} defines a partial order on $\part(\leaves)$.
Specifically, for $\zeta,\zeta'\in{\part(\leaves)}$, we say $\zeta\preceq{\zeta'}$ if and only if for every $b'\in{\zeta'}$ there is $b\in{\zeta}$ such that $b\supseteq{b'}$.
The tree structure of $G$ is defined by a \cadlag\ map $Z:[0,T]\to\part(\leaves)$ that is monotone in the sense that $t_1\le{t_2}$ implies $Z_{t_1}\preceq{Z_{t_2}}$.
An element $b\in{Z_t}$ is a set of labels;
it represents the branch of the tree that bears the corresponding lineages.
We use the notation $\event{Z}$ to denote the set of times at which $Z$ is discontinuous.
Note that $\event{Z}$ includes the times of all tip, sample, and branch-point nodes, but excludes inline and root nodes.
Therefore, $\event{Z}\subseteq{\event{G}}$.

The third element of $G$ specifies the coloring of branches and locations of tip, sample, and internal nodes (including inline nodes).
Mathematically, if $G=(T,Z,Y)$, then $Y$ is a \cadlag\ function that maps each point on the genealogy to a deme and a non-negative integer.
In particular, if $t\in[0,T]$ and $a$ is the label of any tip or sample node,
$Y_t(a)=(Y_t^{\lab{d}}(a),Y_t^{\lab{m}}(a))\in\Demes\times\Zp$, where $Y_t^{\lab{d}}(a)$ is the deme in which the lineage of $a$ is located at time $t$ and $Y_t^{\lab{m}}(a)$ is the number of internal or sample nodes encountered along the lineage of $a$ in going from time $0$ to time $t$.
In particular, $Y_t^{\lab{m}}(a)$ is a simple counting process, with $Y_0^{\lab{m}}(a)=0$ for all $a$.
Since $a,a'\in{b}\in{Z_t}$ implies $Y_t(a)=Y_t(a')$, one can equally well think of $Y_t$ as a map $Z_t\to\Demes\times\Zp$.
Given a tree $Z$, we let $\func{Y}(Z)$ denote the set of colorings $Y$ that are compatible with $Z$ and $\func{Y}_t(Z)\coloneq\CondSet{Y_t}{Y\in{\func{Y}(Z)}}$.

\AAK{[Formally speaking, the set of possible colorings is a section of a fiber bundle over $Z$, where each fiber is the coloring at a given time.]}

It will sometimes be convenient to make use of notation whereby a genealogy $G=(\time(G),G^{\lab{Z}},G^{\lab{Y}})$.

\subsection{Binomial ratio}
\label{sec:binomial_ratio}

For $n,r,\ell,s\in{\Zp^\Demes}$, define the \emph{binomial ratio}
\begin{equation*}
  \BinRatio{n}{\ell}{r}{s}\colonequals
  \begin{cases}
    \frac{\displaystyle\prod_{i\in\Demes}{\binom{n_i-\ell_i}{r_i-s_i}}}%
         {\displaystyle\prod_{i\in\Demes}{\binom{n_i}{r_i}}},
         & \text{if}\ \forall i\ n_i\ge{\Set{\ell_i,r_i}}\ge{s_i}\ge{0},\\
         0, & \text{otherwise}.
  \end{cases}
\end{equation*}
Observe that $\BinRatio{n}{\ell}{r}{s}\in{[0,1]}$.
Moreover, in consequence of the Chu-Vandermonde identity, we have
\begin{equation*}
  \sum_{s\in\Zp^{\Demes}}\BinRatio{n}{\ell}{r}{s}\binom{\ell}{s}=1,
\end{equation*}
whenever $n_i\ge{\Set{\ell_i,r_i}}\ge{0}$ for all $i$.

\section{The induced genealogy process}

\subsection{Event types}
\label{sec:event_types}

We will show how a given population process naturally induces a process in the space of genealogies.
Specifically, we will describe how, at each jump in the population process, a corresponding change occurs in the genealogy, according to whether lineages branch, die, move between demes, or are sampled.
For this purpose, there are five distinct \emph{pure types} of events:
\begin{compactenum}[(a)]
\item \emph{Birth-type events} result in the branching of one or more new lineages, each from some existing lineages.
  Examples of birth-type events include transmission events, speciations, and actual births.
  Importantly, we assume that all new lineages arising from a birth event share the same parent and that  at most one birth event occurs at a time, almost surely.
\item \emph{Death-type events} result in the extinction of one or more lineages.
  Examples include recovery from infection, death of a host, and species extinctions.
  We allow for the possibility that multiple lineages die simultaneously.
\item \emph{Migration-type events} result in the movement of a lineage from one deme to another.
  Spatial movements, changes in host age or behavior, and progression of an infection can all be represented as migration-type events.
  We permit multiple lineages to move simultaneously.
\item \emph{Sample-type events} result in the collection of a sample from a lineage but do not in themselves affect the inventory process.
  We allow for the possibility that multiple samples are collected simultaneously, though we require that, in this case, each extant lineage is sampled at most once.
\item \emph{Neutral-type events} result in no change to any of the lineages.
\end{compactenum}
\Cref{fig:markov_state} depicts an example with jumps of all five pure types.
It is not necessary that an event be of a pure type;
\emph{compound events} partake of more than one type.
For example, a sample/death-type event, in which a lineage is simultaneously sampled and removed, has been proposed \citep{Leventhal2014}, as have birth/death events in which one lineage reproduces at the same moment that another dies (\eg the \citet{Moran1958} process).
The theory presented here places few restrictions on the complexity of the events that can occur by combining events of the various pure types.

%% Because different kinds of events may differ not only in the number of offspring they engender, but also in the number of parent lineages, and the distribution of offspring among parents and demes, there is implicitly a deterministic indicator function $Q_u$, for $u\in\Jumps$, (described below) that captures these properties.

\subsection{Genealogy process}

We now show how a given population process induces a stochastic process, $\Gr_t$, on the space of genealogies.
In the case of unstructured population processes (\ie those having a single deme), \citet{King2022} gave a related construction that is equivalent to the one presented here.

\begin{figure}
  \input{figs/event_types}
\end{figure}

At each jump in the population process, a change is made to the genealogy, according to the mark, $u$, of the jump (\cref{fig:event_types}).
In particular:
\begin{compactenum}[(a)]
\item
  If $u$ is of birth-type (\cref{fig:event_types}A), it results in the creation of one new internal node, call it $b$.
  A tip node, $a$, of the appropriate deme is chosen with uniform probability from among those present and $b$ is inserted so that its ancestor is that of $a$, while $a$ takes $b$ as its ancestor.
  One new tip node, of the appropriate deme, is created for each of the children, all of which take $b$ as their immediate ancestor.
\item
  If $u$ is of death-type (\cref{fig:event_types}B), one or more tip nodes of the appropriate demes are selected with uniform probability from among those present.
  These are deleted.
  Next, branch nodes without children are recursively removed.
  Sample nodes are never removed.
\item
  At a migration-type event (\cref{fig:event_types}C), the appropriate number of migrating lineages are selected at random with uniform probability, from among those present in the appropriate demes.
  For each selected lineage, one new branch node is inserted between the selected tip node and its ancestor.
  The color of the descendant branch changes accordingly.
\item
  At a sample-type event (\cref{fig:event_types}D), the appropriate number of sampled lineages are selected at random from among the tip nodes, with uniform probability according to deme.
  One new sample node is introduced for each selected lineage:
  each is inserted between a selected tip nodes and its ancestor.
\item
  At a neutral-type event (\cref{fig:event_types}E), no change is made to the genealogy.
\item
  Finally, events of compound type (\eg \cref{fig:event_types}F--H) are accommodated by combining the foregoing rules.
\end{compactenum}
In each of these events, the new node or nodes that are introduced have node-times equal to the time of the jump.

\subsubsection{Emergent lineages and production}

The lineages which descend from an inserted node are said to \emph{emerge} from the event.
Thus, after a birth-type event, the emerging lineages include all the new offspring as well as the parent.
Likewise, at pure migration- or sample-type events, each migrating or sampled lineage emerges from the event.
At pure death-type events, no lineages emerge.
In general, at an event of mark $u$, there are $r^u_i$ emergent lineages in deme $i$.
We require that $r^u_i$ be a constant, for each $u$ and $i$.
Since, in applications, one is free to expand the set of jump-marks $\Jumps$ as needed, this is not an important restriction on the models that the theory can accommodate.
Thus there is a function $r:\Jumps\times\Demes\to\Zp$, such that $r^u_i$ lineages of deme $i$ emerge from each event of mark $u$.
We say $r^u=(r^u_i)_{i\in\Demes}$ is the \emph{production} of an event of mark $u$.
Note that the lineages that die as a result of an event do not count in the production but that a parent lineage that survives the event does count.

\subsubsection{Conditional independence and exchangeability}

Application of these rules at each jump of $\Xr_t$ constructs a chain of genealogies $\Grh_k$.
In particular, at each jump-time $\Trh_k$, the genealogy $\Grh_{k-1}$ is modified according to the jump-mark $\Urh_k$ to yield $\Grh_k$.
We view $\Grh_k$ as the embedded chain of the continuous-time genealogy process $\Gr_t$.
It is very important to note that, conditional on $(\Xrh_k,\Urh_k)$, the number of parents and number of offspring in each deme is determined and the random choice of which lineages die, migrate, are sampled, or sire offspring is independent of these choices at any other times and independent of $(\Xrh_j,\Urh_j)$ for all $j\ne{k}$.
Moreover, by construction, any lineage within a deme is as likely as any other lineage in that deme to be selected as a parent or for death, sampling, or migration.
We refer to this property as the \emph{exchangeability} of lineages within a deme.
Finally, note that $\Gr_t$ does not have the Markov property, though $(\Xr_t,\Ur_t,\Gr_t)$ and $(\Xr_t,\Gr_t)$ do.

\subsection{Pruned and obscured genealogies}

\begin{figure}
  <<upo,fig.dim=c(4,6),out.width="50%">>=
  freeze(
    seed=522390503,
    simulate(
      "SEIR",
      Beta=1,sigma=0.5,gamma=0.1,psi=0.4,omega=0.1,
      S0=10,E0=1,I0=1,R0=0,
      time=10
    )
  ) -> x

  pal <- c("#00274CFF","#FFCB05FF")

  plot_grid(
    A=x |>
      plot(
        points=TRUE,prune=FALSE,obscure=FALSE,
        ladderize=FALSE,palette=pal
      )+
      geom_vline(xintercept=10,linewidth=0.2,color="black"),
    B=x |>
      plot(
        points=TRUE,prune=TRUE,obscure=FALSE,
        ladderize=FALSE,palette=pal
      )+
      geom_vline(xintercept=10,linewidth=0.2,color="black"),
    C=x |>
      plot(
        points=TRUE,prune=TRUE,obscure=TRUE,
        ladderize=FALSE,palette="#B3B3B3FF"
      )+
      geom_vline(xintercept=10,linewidth=0.2,color="black"),
    ncol=1,
    align="hv",axis="tblr",
    labels="AUTO"
  )
  @
  \caption{
    Unpruned, pruned, and obscured genealogies from a single realization of the genealogy process induced by the SEIRS model depicted in \cref{fig:example_models,fig:markov_state}.
    \textbf{(A)} A realization of the unpruned genealogy process $\Gr_t$ is shown at $t=10$.
    Tip nodes, corresponding to lineages alive at time $t=10$ are indicated with black points.
    Blue points represent samples;
    green points, internal nodes.
    Branches are colored according to the deme in which the corresponding lineage resided at that point in time:
    blue denotes $\lab{E}$ and yellow, $\lab{I}$.
    \textbf{(B)} The genealogy is \emph{pruned} by deleting all tip nodes and then recursively pruning away childless internal nodes.
    Sample nodes are never removed.
    \textbf{(C)} A genealogy is \emph{obscured} by effacing all deme information from lineage histories:
    the colors are erased, as are all inline nodes.
    See the text (\cref{sec:genealogy,sec:pruning,sec:obscuration}) for more detail.
    \label{fig:upo}
  }
\end{figure}

The process just described yields a genealogy that relates all extant members of the population, and all samples.
Moreover, it details each lineage's complete history of movement through the various demes.
The data we ultimately wish to analyze will be based only on samples, however.
Nor, in general, will the histories of deme occupancy be observable.
A generative model must account for this loss of information.
We therefore now describe how genealogies are \emph{pruned} to yield sample-only genealogies and then \emph{obscured} via the erasure of color from their branches (\cref{fig:upo}).

\subsubsection{Pruned genealogy}
\label{sec:pruning}

Given a genealogy $G$, one obtains the \emph{pruned genealogy}, $P=\prune(G)$ by first dropping every tip node and then recursively dropping every childless internal node (\cref{fig:upo}A--B).
In a pruned genealogy only internal and sample nodes remain, and sample nodes are found at all of the leaves and possibly some of the interior nodes of the genealogy.
Observe that a pruned genealogy is a colored genealogy:
it retains information about where among the demes each of its lineages was through time (\cref{fig:upo}B).
Note also that a pruned genealogy $P$ is characterized by its time, $\time(P)$ and the functions $P^{\lab{Y}}$ and $P^{\lab{Z}}$ just as an un-pruned genealogy is.
Finally, observe that, since it contains within itself all of its past history, the pruned genealogy process $\Pr_t=\prune(\Gr_t)$ is Markov, even though the unpruned genealogy process, $\Gr_t$, is not.

\subsubsection{Lineage count and saturation}
\label{sec:ells}

In the following, we will find that we need to count the deme-specific numbers of lineages present in a given pruned genealogy at a given time.
Accordingly, suppose $P=(T,Z,Y)$ is a pruned genealogy and suppose $t\in[0,T]$.
Let $\ell_i$ denote the number of lineages in deme $i$ at time $t$ and $\ell=(\ell_i)_{i\in\Demes}\in\Zp^{\Demes}$.
Clearly, $\ell$ depends only $Y_t$.
Therefore, we can define $\ell$ as a function such that, whenever $P=(T,Z,Y)$ is a pruned genealogy, $\ell(Y_t)$ is the vector of deme-specific lineage counts at time $t$.
We refer to $\ell$ as the \emph{lineage-count} function (cf.~\cref{fig:ells}).

We will also have occasion to refer to the deme-specific number of lineages emerging from a given event.
In particular, given a node time $t$ in a pruned genealogy $P=(T,Y,Z)$, the number $s_i$ of lineages of deme $i$ emerging from all nodes with time $t$ is well defined and we can write $s=\left(s_i\right)_{i\in\Demes}$.
Like the lineage-count function, $s$ depends only on the local structure of $\P$.
However, $s$ depends not only on $Y_t$, but also on $\leftlim{Y}_t$.
Thus, we can define the \emph{saturation} function such that, whenever $P=(T,Y,Z)$ is a pruned genealogy, $s(\leftlim{Y}_t,Y_t)$ is the integer vector of deme-specific numbers of emerging lineages at time $t$.
\Cref{fig:ells} illustrates.

\begin{figure}
  \input{figs/ells}
\end{figure}

\subsubsection{Compatibility}
\label{sec:compatibility}

Suppose $P$ is a pruned genealogy, with $\time(P)=T$ and $t\in\event{P}$.
The local structure of $P$ at $t$ is, in general, compatible with only a subset of the possible jumps $\Jumps$.
For example, if the event in $P$ at $t$ is a branch node or a sample node, then it is compatible only with birth-type or sample-type jumps, respectively.
Similarly, if the node in $P$ at time $t$ is one at which a lineage moves from deme $i$ to deme $i'$, then $u$ must be either of $i\to{i'}$ migration type or of a birth type with parent in $i$ and $r^u_{i'}>0$.
To succinctly accommodate all possibilities, let us introduce the indicator function $Q$ such that $Q=1$ if the local genealogy structure---which is captured by the values of $P^{\lab{Y}}$ just before and after $t$---is compatible with an event of type $u$ and $Q=0$ otherwise.
That is, $Q_u(\eta,\eta')=1$ if and only if
there is a feasible genealogy, $\G=(\T,\Z,\Y)$, and history, $\H$,
and a $t\in{[0,\T]}$ such that,
given $\Gr_\T=\G$ and $\Hr_\T=\H$,
we have $\U_t=u$, $\Yt_t=\eta$, and $\Y_t=\eta'$.
We refer to $Q$ as the \emph{compatibility indicator}.

\subsubsection{Obscured genealogy}
\label{sec:obscuration}

The \emph{obscured genealogy} is obtained by discarding all information about demes and events not visible from the topology of the tree alone (\cref{fig:upo}B--C).
In particular, if $P=(T,Z,Y)$ is a pruned genealogy, we write $\obs(P)=(T,Z)$ to denote the obscured genealogy.

\section{Results}

\subsection{Likelihood for pruned genealogies}

Our first result will be an expression for the likelihood of a given pruned genealogy given the history of the population process.

\begin{thm}\label{thm:pruned_lik}
  Suppose $\P=(\T,\Z,\Y)$ is a given pruned genealogy.
  Define
  \begin{equation}\label{eq:phidef}
    \phi_u(x,y,y')\coloneq\BinRatio{n(x)}{\ell(y')}{r^{u}}{s(y,y')}\,Q_{u}(y,y'),
  \end{equation}
  where $n$ is the deme occupancy (\cref{sec:demes}), $\ell$ and $s$ are the lineage-count and saturation functions, respectively (\cref{sec:ells}), $Q$ is the compatibility indicator (\cref{sec:compatibility}), and the binomial ratio is as defined in \cref{sec:binomial_ratio}.
  Then
  \begin{equation*}
    \CondProb{\Pr_\T=\P}{\Hr_\T=\H}=\Indicator{\event{\H}\supseteq{\event{\P}}}\,\prod_{t\in\event{\H}}{\phi_{\U_t}(\X_t,\Yt_t,\Y_t)}.
  \end{equation*}
\end{thm}
\begin{proof}
  If $\event{\H}\nsupseteq\event{\P}$, then $\H$ and $\P$ are incompatible and $\CondProb{\Pr_\T=\P}{\Hr_\T=\H}=0$.
  Similarly, if any event of $\H$ is incompatible with the local structure of $\P$ in the sense of \cref{sec:compatibility}, then $\CondProb{\Pr_\T=\P}{\Hr_\T=\H}=0$.
  Let us therefore suppose that neither of these conditions hold.
  Conditional on $\Hr_\T=\H$, at each time $t\in\event{\H}$, a jump of mark $\U_t$ occured, with a production of $r^{\U_t}=(r_i)_{i\in\Demes}$, resulting in a deme-occupancy of $n(\X_t)=(n_i)_{i\in\Demes}$.
  In $\P$, at time $t$, there are $\ell_i=\ell_i(\Y_t)$ lineages in deme $i$, of which $s_i=s_i(\Yt_t,\Y_t)$ are emergent.
  By assumption, at each genealogical event, lineages within a deme are exchangeable:
  each has an identical probability of being involved.
  This exchangeability implies that each lineage present in a deme at time $t$ was equally likely to have been one of the emergent lineages.
  In particular, at time $t$, the probability that $s_i$ of the $\ell_i$ deme-$i$ lineages were among the $r_i$ of $n_i$ lineages emergent in the inventory process is the same as the probability that, upon drawing $\ell_i$ balls without replacement from an urn containing $r_i$ red balls and $n_i-r_i$ black balls, exactly $s_i$ of the drawn balls are red, namely
  \begin{equation*}
    \frac{\binom{n_i-\ell_i}{r_i-s_i}\,\binom{\ell_i}{s_i}}{\binom{n_i}{r_i}}.
  \end{equation*}
  Because our lineages are labelled, each of the $\binom{\ell_i}{s_i}$ equally probable sets of $s_i$ lineages is distinct;
  just one of these is the one present in $\P$.
  Moreover, since, again conditional on $\Hr_\T=\H$, the identities of the lineages involved in a genealogical event are random and independent of the identities selected at all other events, we have established that
  \begin{equation*}
    \CondProb{\Pr_\T=\P}{\Hr_\T=\H}=\prod_{t\in\event{\H}}{\BinRatio{n(\X_t)}{\ell(\Y_t)}{r^{\U_t}}{s(\Yt_t,\Y_t)}}.
  \end{equation*}
  Returning to the possibility that $\H$ is incompatible with $\P$, since $\Prob{\Pr_\T=\P}=0$ if either any $Q_u=0$ or $\event{\P}\nsubseteq\event{\H}$, we obtain the result.
\end{proof}

%% \begin{equation*}
%%   \phi_u(\xi,\eta,\eta')\colonequals\BinRatio{n(\xi)}{\ell(\eta')}{r^u}{s(\eta,\eta')}\,Q_u(\eta,\eta').
%% \end{equation*}

Next, we show how the likelihood of a pruned genealogies, unconditional on the history, can be computed.
For this, we use the filter equation technology developed in \cref{sec:filter_eqns}.
In particular, the following theorem follows immediately from \cref{lemma:sing-filt}.

\begin{corol}
  Suppose that $\P=(\T,\Z,\Y)$ is a given pruned genealogy.
  Suppose that $w=w(t,x)$ satisfies the initial condition $w(0,x)=p_0(x)$ and the filter equation
  \begin{equation}
    \begin{aligned}
      \frac{\partial{w}}{\partial{t}}(t,x)=
      &\sum_u{\int{w(t,x')\,\alpha_u(t,x',x)\,\phi_u(x,\Yt_t,\Y_t)\,\dd{x'}}}
      -\sum_u{\int{w(t,x)\,\alpha_u(t,x,x')\,\dd{x'}}},
      &t\notin{\event{\P}},\\
      w(t,x)=&\sum_u{\int{\wt(t,x')\,\alpha_u(t,x',x)\,\phi_u(x,\Yt_t,\Y_t)\,\dd{x'}}},
      &t\in{\event{\P}},
    \end{aligned}
  \end{equation}
  where $\phi$ is defined in \cref{eq:phidef}.
  Then the likelihood of $\P$ is
  \begin{equation*}
    \lik(\P)=\int{w(T,x)\,\dd{x}}.
  \end{equation*}
\end{corol}

\subsection{Likelihood for obscured genealogies}

Our next result concerns the likelihood of a given obscured genealogy conditional on the history.

\begin{thm}\label{thm:obsc_lik}
  Suppose that $(\T,\Z)$ is a given obscured genealogy.
  Let $q$ and $\pi$ be probability kernels, such that
  for all $x\in\Xspace$ and $y\in\func{Y}_0(\Z)$,
  \begin{equation*}
    \begin{gathered}
      q(x,y)\ge{0},\qquad
      \sum_{y\in\func{Y}_0(\Z)}{q(x,y)}=1,
    \end{gathered}
  \end{equation*}
  and, for all $u\in\Jumps$, $t\in\Rp$, $x,x'\in\Xspace$, $y,y'\in\func{Y}_t(\Z)$,
  \begin{equation*}
    \begin{gathered}
      \pi_u(t,x,x',y,y')\ge{0},\qquad
      \sum_{y'\in\func{Y}_t(\Z)}{\pi_u(t,x,x',y,y')}=1.
    \end{gathered}
  \end{equation*}
  Suppose moreover that $\pi_u(t,x,x',y,y')>0$ whenever $\alpha_u(t,x,x')\,Q_u(y,y')>0$
  and that $q(x,y)>0$ whenever $\CondProb{\Pr_0^{\lab{Y}}=y}{\Xr_0=x}>0$.
  Then there is a stochastic jump process $\yr_t$ with sample paths in $\func{Y}(\Z)$ such that $(\Xr_t,\Ur_t,\yr_t)$ is Markov and
  \begin{equation*}
    \CondProb{\Pr^{\lab{Z}}_\T=\Z}{\Hr_\T=\H}=
    \Indicator{\event{\H}\supseteq\event{\Z}}\,\Expect{\frac{1}{q(X_0,\yr_0)}\,\prod_{t\in\event{\H}}{\frac{\phi_{\U_t}(\X_t,\yrt_t,\yr_t)}{\pi_{\U_t}(t,\Xt_t,\X_t,\yrt_t,\yr_t)}}},
  \end{equation*}
  where $\phi$ is defined in \cref{eq:phidef} and
  the expectation is taken over the sample paths of $\yr_t$.
\end{thm}
\begin{proof}
  First, observe that, since $\obs$ is a deterministic operator,
  \begin{equation}\label{eq:IS1}
    \CondProb{\Pr^{\lab{Z}}_\T=\Z}{\Hr_\T=\H}=\CondExpect{\Indicator{\Pr^{\lab{Z}}_\T=\Z}}{\Hr_\T=\H}.
  \end{equation}
  Our strategy will be to evaluate \cref{eq:IS1} using importance sampling:
  we will propose pruned genealogies compatible with $\Z$ as sample paths from a stochastic process driven by $\Xr_t$ and
  evaluate the the expectation in \cref{eq:IS1} by summing over these paths.
  Conditional on $\Hr_\T=\H$, the initial distribution $q$ and probability kernel $\pi$ generate a Markov chain, $\yrh_k$ such that
  \begin{equation*}
    \begin{gathered}
      \CondProb{\yrh_0}{\Hr_\T=\H}=q(\X_0,\yrh_0),
      \qquad
      \CondProb{\yrh_k}{\yrh_{k-1},\Hr_\T=\H}=\pi_{\Uh_k}(\Th_k,\Xh_{k-1},\Xh_{k},\yrh_{k-1},\yrh_k).
    \end{gathered}
  \end{equation*}
  The required process $\yr_t$ is the unique \cadlag\ process with event times $\Th_k$ and $\yrh_k$ as its embedded chain.
  This construction of $\yr_t$ obviously guarantees that $\event{\H}\supseteq\event{\yr}\supseteq\event{\Z}$ and that $(\Xr_t,\Ur_t,\yr_t)$ is Markov.

  Now, for $\y\in\func{Y}(\Z)$, let us define $C(\y)=(\T,\Z,\y)$.
  Then, by construction, $\obs(C(\y))=(\T,\Z)$ and,
  conversely, for every pruned genealogy $\P$ satisfying $\time(\P)=\T$ and $\P^{\lab{Z}}=\Z$, $C(\P^{\lab{Y}})=\P$.
  Moreover, the conditions on the kernels $q$ and $\pi$ guarantee that, if $\CondProb{\Pr_\T=\P}{\Hr_\T=\H}>0$ and $\P^{\lab{Z}}=\Z$, then $\CondProb{\yr=\P^{\lab{Y}}}{\Hr_\T=\H}>0$.
  We therefore have that
  \begin{equation*}
    \CondProb{\Pr^{\lab{Z}}_\T=\Z}{\Hr_\T=\H}=
    \Expect{\frac{\CondProb{\Pr_\T=C(\yr)}{\Hr_\T=\H}}{\pi(\yr\vert\H)}},
  \end{equation*}
  the expectation being taken with respect to the random process $\yr$.
  Here, by definition,
  \begin{equation*}
    \pi(\yr\vert\H)=q(\X_0,\yr_0)\,\prod_{t\in\event{\H}}{\pi_{\U_{t}}(t,\Xt_{t},\X_{t},\yrt_{t},\yr_{t})}.
  \end{equation*}
  The result then follows from \cref{thm:pruned_lik}.
\end{proof}

The final result shows how to compute the likelihood of an obscured genealogy.
It is an immediate consequence of \cref{thm:obsc_lik,lemma:sing-filt}.

\begin{corol}
  Let $V=(\T,\Z)$ be a given obscured genealogy.
  Then there are probability kernels $q$ and $\pi$ as in \cref{thm:obsc_lik} such that if
  \begin{equation*}
    \begin{gathered}
      \beta_u(t,x,x',y,y')=\alpha_u(t,x,x')\,\pi_u(t,x,x',y,y'),\qquad
      \psi_u(t,x,x',y,y')=\frac{\phi_u(x',y,y')}{\pi_u(t,x,x',y,y')},
    \end{gathered}
  \end{equation*}
  and if $w=w(t,x,y)$ satisfies
  the initial condition $w(0,x,y)=p_0(x)\,\Indicator{q(x,y)>0}$
  and the filter equation
  \begin{equation*}
    \begin{aligned}
      &\frac{\partial{w}}{\partial{t}}=
      \sum_{uy'}{\int{w(t,x',y')\,\beta_u(t,x',x,y',y)\,\psi_u(t,x',x,y',y)\,\dd{x'}}}
      -\sum_{uy'}{\int{w(t,x,y)\,\beta_u(t,x,x',y,y')\,\dd{x'}}},
      &t\in{\event{\Z}},\\
      &w(t,x,y)=\sum_{uy'}{\int{\wt(t,x',y')\,\beta_u(t,x',x,y',y)\,\psi_u(t,x',x,y',y)\,\dd{x'}}},
      &t\in{\event{\Z}},
    \end{aligned}
  \end{equation*}
  then the likelihood of $V$ is
  \begin{equation*}
    \lik(V)=\sum_y{\int{w(T,x,y)\,\dd{x}}}.
  \end{equation*}
\end{corol}

\begin{remark}
  Note that, since $\func{Y}_t(\Z)$ is finite, it is permissible to choose $q$ and $\pi$ to be uniform.
\end{remark}

Lemmas in the appendix show how this can be computed via Sequential Monte Carlo.


\section{Examples}

\subsection{SIRS}

Was shown in an earlier paper.
[Display filter equation and plot a curve.]

\subsection{SEIRS}

Display filter equation.
Discuss the choice of $\pi$ and $q$.
Present a likelihood curve.

\subsection{Two-strain competition}

Display filter equation.
Discuss the choice of $\pi$ and $q$.
Present a likelihood curve.

\subsection{Superspreading model}

Display filter equation.
Discuss the choice of $\pi$ and $q$.
Present a likelihood curve.

\subsection{Linear birth-death and Moran models}

Exact solution of the filtering equations is possible in the unstructured case, yielding precisely the likelihoods for these two models.
This establishes that the present theory is a strict generalization of these cases.
It does away with the need for large sample-size and small sample-fraction approximations, the necessity of assuming slow changes in effective population size, and the need for linearization.

\section{Discussion}

Generalization of coalescent and birth-death process approaches.
Both Moran model and birth-death processes are special cases.

Allows models with demographic stochasticity.
Incorporating environmental stochasticity is likely possible:
extension to stochastic processes with a diffusion component.

Freedom to choose models with many demes.
Freedom to choose model of sampling.

Price of flexibility is variability in the Monte Carlo estimation.
Freedom to choose importance sampling distribution.
It is permissible to borrow information from the future.

Filter equation formalism suggests approximations based on discretization of time.


\bibliographystyle{preprint}
\bibliography{phylopomp}

\appendix
\setcounter{equation}{0}
\titleformat{\section}[hang]{\large\bfseries}{Appendix \periodafter\thesection}{2ex}{\periodafter}{}
\renewcommand{\theequation}{\thesection\arabic{equation}}

\section{Filter equations}
\label{sec:filter_eqns}

Explicit expressions for the quantities that arise in this paper are not always readily available.
Here, we develop tools for manipulating complex expressions that are otherwise cumbersome.

\begin{defn}
  Suppose $\Xr_t$ is a continuous-time Markov process with Kolmogorov forward equation (KFE)
  \begin{equation}
    \label{eq:kfe2}
    \frac{\partial{u}}{\partial{t}}(t,x)
    =\int{u(t,x')\,\beta(t,x',x)\,\dd{x'}}
    -\int{u(t,x)\,\beta(t,x,x')\,\dd{x'}}.
  \end{equation}
  Suppose that $B(t,x,x')\ge{0}$ and $\lambda(t,x)$ are given, real-valued, measurable functions.
  We say that the equation
  \begin{equation}
    \label{eq:reg-filter-eq}
    \begin{aligned}
      \frac{\partial{w}}{\partial{t}}(t,x)
      =&\int{w(t,x')\,\beta(t,x',x)\,B(t,x',x)\,\dd{x'}}
      -\int{w(t,x)\,\beta(t,x,x')\,\dd{x'}}
      -\lambda(t,x)\,w(t,x).\\
    \end{aligned}
  \end{equation}
  is the \emph{filter equation} with \emph{driver} $\Xr_t$ (or \emph{generated by} $\beta$), \emph{boost} $B$, and \emph{decay} $\lambda$.
\end{defn}

\begin{remark}
  Trivially, a Kolmogorov forward equation is itself a filter equation with boost $1$ and decay $0$.
\end{remark}

\AAK{[We should define the singular filter equations (\ie those with a discrete portion) also.]}

The following results show how filter equations allow one to integrate over random histories.

\begin{lemma}
  \label{lemma:reg-filt}
  Suppose that $B:\Rp\times\Xspace^2\to\Rp$ is measurable.
  If $\Vr_t$ is an $\Rp$-valued random process satisfying
  \begin{equation*}
    \CondExpect{\Vr_t}{\Hr_t=\H_t}=\prod_{e\in\event{\H_t}}{B(e,\Xt_e,\X_e)},
  \end{equation*}
  then $\CondExpect{\Vr_t}{\Xr_t=x}$ is a measure-valued deterministic process on $\Xspace$ with density $w(t,x)$ that satisfies the filter equation
  \begin{equation}
    \label{eq:reg-filter-eq2}
    \frac{\partial{w}}{\partial{t}}=\int{w(t,x')\,\alpha(t,x',x)\,B(t,x',x)\,\dd{x'}}-\int{w(t,x)\,\alpha(t,x,x')\,\dd{x'}}.
  \end{equation}
  Moreover, $\Expect{\Vr_t}=\int{w(t,x)\,\dd{x}}$.
\end{lemma}
\begin{proof}
  The expectation can be broken into three terms, according to whether $\H_t$ has zero, one, or more than one event in $\halfclosed{t-\Delta,t}$.
  Accordingly, as $\Delta\downarrow{0}$,
  \begin{equation*}
    \begin{aligned}
      w(t,x)=&\left(1-\Delta\,\int{\alpha(t-\Delta,x,x')\,\dd{x'}}\right)\,w(t-\Delta,x)\\
      &\qquad+\Delta\,\int{\alpha(t-\Delta,x',x)\,B(t-\Delta,x',x)\,w(t-\Delta,x')\,\dd{x'}}+o(\Delta).
    \end{aligned}
  \end{equation*}
  In the limit, we obtain \cref{eq:reg-filter-eq}.
  The last statement follows by definition.
\end{proof}

\begin{lemma}
  \label{lemma:sing-filt}
  Suppose $\mathcal{M}\subset{\Rp}$ is countable such that $\mathcal{M}_t\coloneq\mathcal{M}\cap{[0,t]}$ is finite for all $t$.
  Suppose that $B:\Rp\times\Xspace^2\to\Rp$ is measurable and
  $\Vr_t$ is an $\Rp$-valued process satisfying
  \begin{equation*}
    \CondExpect{\Vr_t}{\Hr_t=\H_t}=\Indicator{\event{\H_{t}}\supseteq\mathcal{M}_t}\,\prod_{e\in\event{\H_{t}}}{B(e,\Xt_e,\X_e)}.
  \end{equation*}
  Then $\CondExpect{\Vr_t}{\Xr_t=x}$ is a measure-valued process on $\Rp^{\vert\mathcal{M}_t\vert}\times\Xspace$ with density $w(t,x)$ that satisfies
  \begin{equation}
    \label{eq:two-part-filter}
    \begin{aligned}
      \frac{\partial{w}}{\partial{t}}(t,x)&=
      \int{w(t,x')\,\alpha(t,x',x)\,B(t,x',x)\,\dd{x'}}-\int{w(t,x)\,\alpha(t,x,x')\,\dd{x'}},\qquad
      &t\notin{\mathcal{M}},\\
      w(t,x)&=\int{\wt(t,x')\,\alpha(t,x',x)\,B(t,x',x)\,\dd{x'}},\qquad
      &t\in{\mathcal{M}}.
    \end{aligned}
  \end{equation}
  Moreover, $\Expect{\Vr_t}=\int{w(t,x)\,\dd{x}}$.
\end{lemma}

\begin{lemma}
  Showing how \cref{eq:two-part-filter} can be stated as a singular filter equation, \ie with driver $\beta$ and boost $C$, where
  \begin{equation*}
    \begin{gathered}
      A(t,x)=\sum_{x'}{\alpha(t,x,x')}, \qquad
      \beta(t,x,x')=\alpha(t,x,x')+\sum_{e\in\mathcal{M}}{\delta(t,e)\,\frac{\alpha(t,x,x')}{A(t,x)}}\,,\\
      C(t,x,x')=B(t,x,x')+\sum_{e\in\mathcal{M}}{\delta(t,e)\,A(t,x)}.
    \end{gathered}
  \end{equation*}
  %% \begin{equation}
  %%   \label{eq:sing-filter-eq}
  %%   \begin{aligned}
  %%     \frac{\partial{w}}{\partial{t}}(t,x)
  %%     =&\int{w(t,x')\,\beta(t,x',x)\,B(t,x',x)\,\dd{x'}}
  %%     -\int{w(t,x)\,\beta(t,x,x')\,\dd{x'}}\\
  %%     &+\sum_e\int{w(t,x')\,\delta(t,e)\,\pi(t,x',x)\,C(t,x',x)\,\dd{x'}}
  %%     -\sum_e\int{w(t,x)\,\delta(t,e)\,\pi(t,x,x')\,\dd{x'}}\\
  %%     &-\lambda(t,x)\,w(t,x).\\
  %%   \end{aligned}
  %% \end{equation}
\end{lemma}

Filter equations afford a convenient means of computing expectations and likelihoods for pure jump processes.
This is facilitated by the following Lemma, the statement of which uses a one-sdied Dirac delta function.
Specifically, let $\delta(v,v')$ be the right-sided Dirac delta function satisfying $\delta(v,v')=0$ for $v\ne{v'}$ and
\begin{equation*}
  \int_a^b{f(v)\,\delta(v,v')\,\dd{v}}=f(v')\,\Indicator{v'\in\halfopen{a,b}},
\end{equation*}
whenever $f$ is \cadlag\ and $-\infty\le{a}<{b}\le{\infty}$.

\begin{lemma}
  \label{lemma:filter}
  The filter equation \eqref{eq:reg-filter-eq} is satisfied by $w(t,x)=\int_0^{\infty}{v\,u(t,x,v)\,\dd{v}}$, where $u(t,x,v)$ satisfies the KFE
  \begin{equation}
    \label{eq:filterlemma}
    \begin{aligned}
      \frac{\partial{u}}{\partial{t}}=
      &\int_0^{\infty}\int{u(t,x',v')\,\beta(t,x',x)\,\delta(v,B(t,x',x)\,v')\,\dd{x'}\,\dd{v'}}\\
      &\qquad-\int_0^{\infty}\int{u(t,x,v)\,\beta(t,x,x')\,\delta(v',B(t,x,x')\,v)\,\dd{x'}\,\dd{v'}}
      +\tfrac{\partial}{\partial{v}}\left[\lambda(t,x)\,v\,u(t,x,v)\right].
    \end{aligned}
  \end{equation}
\end{lemma}
\begin{proof}
  \begin{equation*}
    \begin{aligned}
      \frac{\partial{w}}{\partial{t}}
      =&\int_0^{\infty}{v\,\frac{\partial{u}}{\partial{t}}(t,x,v)\,\dd{v}}\\
      =&\int_0^{\infty}\int\int_0^{\infty}{v\,u(t,x',v')\,\beta(t,x',x)\,\delta(v,B(t,x',x)v')\,\dd{v}\,\dd{x'}\,\dd{v'}}\\
      &\qquad-\int_0^{\infty}\int\int_0^{\infty}{v\,u(t,x,v)\,\beta(t,x,x')\,\delta(v',B(t,x,x')v)\,\dd{v}\,\dd{x'}\,\dd{v'}}\\
      &\qquad+\int_0^{\infty}{v\,\tfrac{\partial}{\partial{v}}\left[\lambda(t,x)\,v\,u(t,x,v)\right]\,\dd{v}}.\\
    \end{aligned}
  \end{equation*}
  Here, the non-explosivity assumption guarantees that we can differentiate under the integral sign and exchange the order of integration.
  Moreover, it ensures that $u\to{0}$ as $v\to{\infty}$.
  Hence, by evaluating the first integral with respect to $v$, the second with respect to $v'$, and the third by parts, we obtain
  \begin{equation*}
    \begin{aligned}
      \frac{\partial{w}}{\partial{t}}
      =&\int{v'\,u(t,x',v')\,\beta(t,x',x)\,B(t,x',x)\,\dd{v'}\,\dd{x'}}
      -\int{v\,u(t,x,v)\,\beta(t,x,x')\,\dd{v}\,\dd{x'}}\\
      &\qquad-\lambda(t,x)\,\int{v\,u(t,x,v)\,\dd{v}},
    \end{aligned}
  \end{equation*}
  which is simplified to obtain \cref{eq:reg-filter-eq}.
\end{proof}

\Cref{eq:filterlemma} is recognizable as the KFE of a certain process $(\Xr_t,\Vr_t)$.
In particular, $\Xr_t$ is the driver with KFE \eqref{eq:kfe2}.
The $\Vr_t$ is \emph{directed} by $\Xr_t$ in the sense that $\Vr$ has jumps wherever $\Xr$ does:
when $\Xr$ jumps at time $t$ from $x$ to $x'$, $\Vr$ jumps by the multiplicative factor $B(t,x,x')\ge{0}$.
Between jumps, $\Vr_t$ decays deterministically and exponentially at rate $\lambda(t,x)$.
If we view $\Vr_t$ as a weight, then \cref{lemma:filter} tells us how the $\Vr_t$-weighted average of $\Xr_t$ evolves in time:
this average is simply $\int\!{w(t,x)\,\dd{x}}$.


%% Filter equations allow us to pass easily between equivalent representations of a process.
%% For example, an equivalent way of representing $\Xr_t$ is in terms of its embedded chain and event times.
%% Let $\Xrh_k$ be the embedded chain of $\Xr_t$ and let $\Trh_k$ be the point process of its event times.
%% It is elementary that
%% \fontsize{10pt}{12pt}\selectfont
%% \begin{equation*}
%%   \begin{gathered}
%%     \Prob{\Xrh_k=\Xh_k\;\Big\vert\;\Xrh_{k-1}=\Xh_{k-1},\Trh_k=\Th_k}=\frac{\alpha(\Th_k,\Xh_{k-1},\Xh_k)}{\int{\alpha(\Th_k,\Xh_{k-1},x')\dd{x'}}},\\
%%     \Prob{\Trh_k>\Trh_{k-1}+t\;\Big\vert\;\Xrh_{k-1}=\Xh_{k-1},\Trh_{k-1}=\Th_{k-1}}=\exp{\left(-\int_{0}^{t}{\int{\alpha(\Th_{k-1}+s,\Xh_{k-1},x')\,\dd{x'}}\,\dd{s}}\right)}.
%%   \end{gathered}
%% \end{equation*}
%% \normalfont
%% Fixing $\nu>0$ and making the definitions,
%% \begin{equation}\label[pluralequation]{eq:nudefs}
%%   \begin{gathered}
%%     A(t,x)=\int{\alpha(t,x,x')\,\dd{x'}}, \qquad
%%     \pi(t,x,x')=\frac{\alpha(t,x,x')}{A(t,x)},\\
%%     B(t,x,x')=\frac{A(t,x)}{\nu}, \qquad
%%     \lambda(t,x)=A(t,x)-\nu,
%%   \end{gathered}
%% \end{equation}
%% we can rewrite the KFE as
%% \begin{equation}\label{eq:poissdriver}
%%   \frac{\partial{w}}{\partial{t}}(t,x)=
%%   \int{w(t,x')\,\nu\,\pi(t,x',x)\,B(t,x,x')\,\dd{x'}}
%%   -\int{w(t,x)\,\nu\,\pi(t,x,x')\,\dd{x'}}
%%   -\lambda(t,x)\,w(t,x).
%% \end{equation}
%% Here, $\nu$ is the intensity of a time-homogenous Poisson process.
%% Note that $\pi$ is the probability kernel of the embedded chain $\Xrh$ and $A(t,x)$ is the intensity of the $\Trh_k$ process.
%% We recognize this equation as the filter equation with boost $B$, decay $\lambda$, and driver generated by $\nu\,\pi(t,x,x')$.
%% It corresponds to the following procedure for simulating $\Xr_t$:
%% \begin{compactenum}[(a)]
%% \item Simulate jump times according to the rate-$\nu$ Poisson process.
%% \item Simulate the embedded chain $\Xrh_k$ using the kernel $\pi$.
%% \item Weight the realization by the product of the $B$ factors.
%%   Note that this makes the appropriate importance-sampling correction.
%% \end{compactenum}

\end{document}
